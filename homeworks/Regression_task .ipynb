{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этом задании Вам предстоит: \n",
    "\n",
    "-познакомиться с предобработкой данных;\n",
    "\n",
    "-найти МНК-решение аналитически;\n",
    "\n",
    "-найти МНК-решение, оптимизируя функцию потерь;\n",
    "\n",
    "-обучить библиотечный алгоритм линейной регрессии;\n",
    "\n",
    "-применить регуляризацию и подобрать лучший параметр для неё;\n",
    "\n",
    "-познакомиться с PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn import preprocessing, cross_validation,  linear_model,  metrics,  pipeline, grid_search\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считываем данные из репозитория UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url='http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
    "data=pd.read_csv(url, sep=',' , header=None, na_values='?')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1) Ознакомьтесь с данными, посмотрите на размер таблицы\n",
    "\n",
    "\n",
    "2) Озаглавьте столбцы\n",
    "\n",
    "3) Посмотрите, есть ли  в последнем столбце (а это наш целевой вектор y) пропуски. Если их немного, просто удалите строки с пропусками\n",
    "\n",
    "4) Создайте вектор y (это последний столбец data), удалите этот столбец из таблицы\n",
    "\n",
    "5) Посмотрите на взаимосвязь признаков с помощью [sns.pairplot](http://seaborn.pydata.org/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка категориальных, количественных и бинарных признаков проходит по-разному. Разделим их, а после обработки соединим снова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)  Создайте 3 списка из имён признаков: категориальные, количественные и бинарные (см. демонстрационные файлы)\n",
    "\n",
    "7) Проверьте, если пропуски в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Заполните пропуски в бинарных признаках. Например, следующим способом "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_bin=data[bin_cols].describe()\n",
    "\n",
    "for c in bin_cols:\n",
    "    top = data_bin[c]['top']\n",
    "    top_items = data[c] == top\n",
    "    data.loc[top_items, c] = 0\n",
    "    data.loc[np.logical_not(top_items), c] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Заполните пропуски в количественных признаках. Например, следующим способом "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_real=data[real_cols].dropna().describe()\n",
    "\n",
    "for c in real_cols:\n",
    "    data[c].fillna(data_real[c].quantile(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Закодируем катигориальные признаки, используя DictVectorizer (см. демонстрационные файлы)\n",
    "\n",
    "10) Запишите закодированные признаки в отдельный массив"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим выборку на обучающую и контрольную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Разделите выборку с помощью **train_test_split** с размером тестовой выборки 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стандартизируем количественные признаки\n",
    "\n",
    "12) Используйте **sklearn.preprocessing.StandardScaler**, запишите стандартизированные данные в новые массивы\n",
    "\n",
    "**NB** Можете попробовать другие методы. Например, **sklearn.preprocessing.normalize**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соедините массивы признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Создайте массивы X_train и  X_test (например, используя np.hstack) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нахождение решения аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Найдите решение нормального уравнения МНК   $F^TF\\alpha=F^Ty$ с помощью [scipy.linalg](https://docs.scipy.org/doc/scipy-0.18.1/reference/linalg.html)\n",
    "\n",
    "15) Найдите минимум функционала ошибки $||F\\alpha-y||^2$ с помощью [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучите линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Посмотрите на метрики качества $R^2 $ и MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрите на коэффициенты, на корреляцию признаков. Присутствует ли мультиколлинеарность? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Посмотрите на получившиеся коэффициенты,соответствующие признакам, используя [zip](https://docs.python.org/2/library/functions.html#zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) **Для количественных признаков:** посмотрите на корреляцию [pandas.DataFrame.corr()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Для категориальных признаков:** вспомните проверку независимости признаков с помощью критерия хи-квадрат.\n",
    "\n",
    "Для столбцов data с категориальными признаками напишите функцию, которая возвращает результат применения  критерия хи-квадрат для таблиц сопряженности. Составьте таблицу сопряженности для каждой пары категориальных признаков (используйте для этого, например, комбинацию **pandas.DataFrame.groupby(['column1', 'column2']).size()** и **pandas.DataFrame.unstack('column1')**. Для полученной таблицы используйте **scipy.stats.chi2_contingency**.\n",
    "\n",
    "Посмотрите на  p-значение для каждой пары признаков. Есть ли связь между признаками?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Для проверки наличия связи между каждой парой категориальныx и количественныx признаков** используйте [ANOVA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html). Также визуализируйте зависимости с помощью [sns.boxplot](http://seaborn.pydata.org/generated/seaborn.boxplot.html?highlight=boxplot#seaborn.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примените регуляризацию, посмотрите, изменилось ли качество\n",
    "\n",
    "19) Обучите Lasso с параметрами по умолчанию, посмотрите на r2 и MSE на тестовой выборке\n",
    "\n",
    "20) Обучите Ridge с параметрами по умолчанию, посмотрите на r2 и MSE на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор параметра регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) С помощью LassoCV подберите лучший параметр  регуляризации из диапазона [1,100] с шагом 5 и постройте график зависимости среднего по фолдам значения MSE от параметра регуляризации (см. демонстрационные файлы). ПО умолчанию используется 3-fold CV.\n",
    "\n",
    "Посмотрите на r2 и MSE на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) Подберите лучший параметр регуляризации из диапазона [1,100] с шагом 5 с помощью RidgeCV.  \n",
    "Имейте в виду, что значения функционала качества на кросс-валидации $cv\\_values\\_ \\ $   доступны, если используется стратегия Leave-One-Out.\n",
    "\n",
    "Посмотрите на r2 и MSE на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) Посмотрите на коэффициенты Lasso и Ridge при лучшем значении  параметра. В чём разница?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Познакомимся с Pipeline. Pipeline позволяет создать модель из несколько последовательных шагов, параметры для этих шагов могут подбираться совместно по кросс-валидации: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "Например, если нам нужно стандартизировать признаки, а затем оценить качество по кросс-валидации, то нужно проводить стандартизацию контрольной и тестовой частей для каждого фолда отдельно. Если мы применим стандартизацию ко всей выборке, а затем проведём кросс-валидацию, то оценки получатся смещёнными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) Применим Pipeline для выбора числа главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classify', LinearRegression())\n",
    "])\n",
    "\n",
    "N_FEATURES_OPTIONS = np.arange(30)[1:]\n",
    "\n",
    "param_grid = {\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "    }\n",
    "\n",
    "grid = grid_search.GridSearchCV(pipe, cv=3, n_jobs=2, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_params_\n",
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
